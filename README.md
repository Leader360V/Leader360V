
# Leader360V : A Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environments

![Leader360V](https://img.shields.io/badge/Dataset-Leader360V-blue)  ![Large_scale](https://img.shields.io/badge/Feature-Large_Scale-red)  ![Real_world](https://img.shields.io/badge/Feature-Real_World-red) 
![Multi_Task_Learning](https://img.shields.io/badge/Feature-Multi_Task_Learning-red)  ![Diverse_Environments](https://img.shields.io/badge/Feature-Diverse_Environments-red) 
![overview](assets/imgs/Teaser_Figure_1_00.png "overview")

## ğŸ“· Quick Demos with Different Scenarios
More results and details can be found on our [ğŸ“– Project Homepage](https://leader360v.github.io/Leader360_Homepage_VUE/). 


<table class="center">
    <tr>
    <td><img src="assets/videos/Basement-Indoor.gif"></td>
    <td><img src="assets/videos/Grassland-Outdoor.gif"></td>
    <td><img src="assets/videos/Gym-Indoor.gif"></td>
    </tr>
</table>
<!-- <p style="margin-left: 2em; margin-top: -1em">Modelï¼š<a href="https://civitai.com/models/30240/toonyou">ToonYou</a><p> -->

<table>
    <tr>
    <td><img src="assets/videos/Nature-Outdoor.gif"></td>
    <td><img src="assets/videos/Road-Outdoor.gif"></td>
    <td><img src="assets/videos/SubwayStation-Indoor.gif"></td>
    </tr>
</table>

## ğŸ“· Quick Demos of Annotation
More results and details can be found on our [ğŸ“– Project Homepage](https://leader360v.github.io/Leader360_Homepage_VUE/). 

<table class="center">
    <tr>
    <td>Raw Videos</td>
    <td>Pipeline Annotation</td>
    <td>Manual Annotation</td>
    </tr>
</table>

<table>
    <tr>
    <td><img src="assets/videos/anno1/raw1.gif"></td>
    <td><img src="assets/videos/anno1/pipe1.gif"></td>
    <td><img src="assets/videos/anno1/manual1.gif"></td>
    </tr>
</table>

<table>
    <tr>
    <td><img src="assets/videos/anno2/raw2.gif"></td>
    <td><img src="assets/videos/anno2/pipe2.gif"></td>
    <td><img src="assets/videos/anno2/manual2.gif"></td>
    </tr>
</table>

<table>
    <tr>
    <td><img src="assets/videos/anno3/raw3.gif"></td>
    <td><img src="assets/videos/anno3/pipe3.gif"></td>
    <td><img src="assets/videos/anno3/manual3.gif"></td>
    </tr>
</table>

ğŸŒŸ For mare details, please refer to our project homepage: 
"[Leader360V : A Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environments](https://leader360v.github.io/Leader360V_HomePage)".

[[ğŸ“Project Homepage](https://leader360v.github.io/Leader360V_HomePage)]

[ğŸ“– Explore More](https://leader360v.github.io/Leader360_Homepage_VUE/)]

[[ğŸ“Š Huggingface Dataset](https://huggingface.co/datasets/Leader360V/Leader360V)]



## About Leader360V

- Leader360V is the first large-scale (10K+), labeled real-world 360 video datasets for instance segmentation and tracking. Our datasets enjoy high scene diversity, ranging from indoor and urban settings to natural and dynamic outdoor scenes.

- All videos in this dataset have undergone standardized preprocessing, including video clipping, facial anonymization for privacy protection, and balanced scene distribution across categories.

- Regarding dataset composition, we integrated existing 360 video datasets (either unlabeled or annotated for single tasks) and supplemented them with newly collected self-recorded videos. All content was then re-annotated to support joint segmentation and tracking tasks.

- **Due to the large size of the dataset, we have currently uploaded only a selection of demos. We plan to upload all files at a later date to facilitate community research.** 


